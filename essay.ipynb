{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27fa68ae-687b-4082-bb3d-6ab26b0c2d5b",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "### Benchmarking State-of-the-Art Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72bae2c",
   "metadata": {},
   "source": [
    "Oleksandra Kovalenko (???)   \n",
    "Cosima Heymann (569413)  \n",
    "Sascha Geyer (546266)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922a67f2",
   "metadata": {},
   "source": [
    "![sentiment](https://camo.githubusercontent.com/899f79e8a2d62fd642eba0791ff66d13d38e427901bfc3cd89c6f613311e1789/68747470733a2f2f6d69726f2e6d656469756d2e636f6d2f70726f78792f312a5f4a57314a614d704b5f6656476c64387064315f4a512e676966 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a171b2ae-0f7f-4590-a943-300e1aabbbd6",
   "metadata": {},
   "source": [
    "### Introduction: What is Sentiment Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a6f362",
   "metadata": {},
   "source": [
    "The growth of user-generated content in web sites and social networks, just to mention a few: Yelp, Twitter, Amazon, Tripadvisor, Rottentomatoes and IMDB has led to an increasing power for expressing opinions. In recent years, the automatic extraction of opinions from a text has become an area of growing interest in Natural Language Processing (NLP). Online opinions have turned into a valuable asset since the fast spreading nature of online content. In order to analyze the massive amount of data, many NLP tasks are being used. In particular, Sentiment Analysis, also known as Opinion Mining (from now on: SA), became an increasingly growing task (Liu, 2015), whose goal it is to classify opinions and sentiments expressed in user-generated text. SA is on the rise due to the increased requirement of analyzing and structuring hidden information, which comes from user-generated content in the form of unstructured data (Ain, Ali, Riaz, Noureen, Kamran, Hayat & Rehman, 2017). It allows to detect the emotion and sentiment that an author of a text felt towards a described subject or entity. It is interesting in many fields and branches and helps solving various tasks, e.g.:\n",
    "\n",
    "- companies are able to measure the feedback about a product or service,\n",
    "- sociologists can look at people’s reaction about certain public events,\n",
    "- psychologists can study the general mind state of communities with regard to various issues, i.e. a depression detection model that is based on SA in micro-blog social networks (Wang, Zhang, Ji, Sun, Wu & Bao, 2013),\n",
    "- governments and political parties are able to correct their actions according to social approval or disapproval,\n",
    "- etc.\n",
    "\n",
    "The challenge is that sentiments are not always expressed explicitly and meanings can be hidden in the context. In these cases, additional word and language knowledge is necessary. Moreover, opinions may involve sarcasm and negations, which can be interpreted differently in various domains and contexts. Sentiment classification is rather easy for humans (Pang, Lee & Vaithyanathan, 2002), but manual review and analysis of texts is very time consuming and expensive. Due to this fact, automatic sentiment classifiers are selected instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff969c0",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis: Definition, Application & Classification \n",
    "\n",
    "Sentiment Analysis is an active research area in NLP that refers to the use of text analysis, statistical learning and often Machine Learning to extract subjective information in source materials such as user-generated texts from social networks, blogs, forums and product or service reviews.\n",
    "Selecting the basic emotions is a difficult task for a computer because of the variety of human emotions. Most of the authors in the NLP community agree on the classification proposed by Ekman, Friesen and Ellsworth (1982) that six basic emotions exist: anger, disgust, fear, joy, sadness and surprise. As such a division requires a complex processing and analysis of the input data, the majority of researchers and authors accept a simpler representation of sentiments according to their polarity (Pang & Lee, 2008). Kurosu (2015) defines sentiment polarity as follows: “The polarity of a sentiment is the point on the evaluation scale that corresponds to our positive or negative evaluation of the meaning of this sentiment.”. Sentiment polarity allows researchers to use a binary or ternary measurement, either positive, negative or neutral and therefore, simplifies the representation and management of the sentiment information. The granularity of SA can be either coarse-grained or fine-grained. Coarse-grained means usually a binary classification (positive, negative). On ther other hand, fine-grained uses for example five possible levels of granularity (high positive, low positive, neutral, low negative, high negative). Liu (2012) presented three levels of SA: document level, sentence level and entity / aspect level. \n",
    "\n",
    "While document level studies the polarity of the whole text with respect to a single entity (e.g. a product), sentence level studies the polarity of single sentences, analyzing clauses and phrases for its sentiment. Contrary, entity / aspect level analyzes what people especially liked or disliked. An entity-aspect might be a single token and its polarity might be different from the overall polarity of the text (Liu, 2012).\n",
    "\n",
    "#####  Application\n",
    "To mention a few application areas:\n",
    "\n",
    "- Social media monitoring,\n",
    "- Customer support / feedback,\n",
    "- Brand monitoring and reputation management,\n",
    "- Voice of customer (VoC),\n",
    "- Voice of employee,\n",
    "- Product analysis,\n",
    "- Market research and competitive research.\n",
    "\n",
    "##### Classification\n",
    "\n",
    "All methods used to solve sentiment classification fall into three main categories: lexicon-based, machine learning-based and hybrid approaches.\n",
    "\n",
    "In lexicon-based approaches, also known as knowledge-based methods, sentiment is seen as a function of keywords and is based on their count. The main task is the construction of sentiment word lexicons with the indicated class labels positive or negative. In some cases also with their intensiveness, which becomes important for a fine-grained classification.\n",
    "\n",
    "An alternative to the knowledge-based method is Machine Learning, which is gaining more and more interest of researchers due to its adaptability and higher accuracy. Traditional Machine Learning methods were the dominant approach in SA (Pang et al., 2002) with the three main algorithms: Naïve Bayes (NB), Support Vector Machines (SVM) and Maximum Entropy (MaxEnt, in Statistics called: Logisitic Regression). Part of Machine Learning models are Deep Learning models (DL) and Transformer models.\n",
    "\n",
    "The hybrid approach, also known as combined analysis or ensemble models, combines both knowledge-based and Machine Learning-based methods and thus, can lead to a superior performance. Researchers were attracted to explore the possibility of a hybrid approach that collectively could exhibit the accuracy of a Machine Learning approach and the speed of a lexical approach.\n",
    "\n",
    "Although traditional Machine Learning algorithms like Support Vector Machines have shown good performance in various NLP tasks for the past decades, they have a few shortcomings, where DL has the potential to overcome these limitations to a large extent and has already shown excellent performance in NLP tasks, including SA (Collobert, Weston, Bottou, Karlen, Kavukcuglu & Kuksa, 2011). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5159d44-5fe5-440b-b8b6-6d5e6333fb21",
   "metadata": {},
   "source": [
    "### Research Overview\n",
    "\n",
    "- brief historical overview\n",
    "- research/literature streams and focus\n",
    "- what is the state-of-the-art research towards 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec6b812",
   "metadata": {},
   "source": [
    "The following section describes related works that exploit different approaches to solve SA tasks on different data sets and from different perspectives in the past 5 years. This review is conducted on the basis of numerous latest studies and researches in the field of SA. The first table presents several methods for English texts, whereas the second literature table mentions a few papers for languages like Greek, German or French. This field of research (SA for different languages) is for sure a topic for future studies.\n",
    "\n",
    "There are several papers that exploit the methods of lexicon-based models, i.e. \n",
    "\n",
    "Hybrid: \n",
    "Gaye B, Zhang D, Wulamu A., 2021\n",
    "Anastasia Novikova, Sergey Stupnikov, 2018\n",
    "Alsayat A, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e127d28",
   "metadata": {},
   "source": [
    "English:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "   <td><strong>Paper Name</strong>\n",
    "   </td>\n",
    "   <td><strong>Year of Publishment</strong>\n",
    "   </td>\n",
    "   <td><strong>Dataset(s)</strong>\n",
    "   </td>\n",
    "   <td><strong>Classification</strong>\n",
    "   </td>\n",
    "   <td><strong>Algorithms</strong>\n",
    "   </td>\n",
    "   <td><strong>Performance Evaluation Criteria</strong>\n",
    "   </td>\n",
    "   <td><strong>Source</strong>\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Explainable Sentiment Analysis: A Hierarchical Transformer-Based Extractive Summarization Approach\n",
    "   </td>\n",
    "   <td>2021\n",
    "   </td>\n",
    "   <td>Large IMDB\n",
    "   </td>\n",
    "   <td>Transformer Models\n",
    "   </td>\n",
    "   <td>Explainable Hierarchical Transformer (ExHiT),  Sentence Classification Combiner Model (SCC)\n",
    "   </td>\n",
    "   <td>Accuracy\n",
    "   </td>\n",
    "   <td><a href=\"https://www.mdpi.com/2079-9292/10/18/2195/pdf\">https://www.mdpi.com/2079-9292/10/18/2195/pdf</a>\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>A Tweet Sentiment Classification Approach Using a Hybrid\n",
    "<p>\n",
    "Stacked Ensemble Technique\n",
    "   </td>\n",
    "   <td>2021\n",
    "   </td>\n",
    "   <td>Sentiment140\n",
    "   </td>\n",
    "   <td>Hybrid of Lexicon-, ML- and DL-based models\n",
    "   </td>\n",
    "   <td>stacked ensemble of three long short-term\n",
    "<p>\n",
    "memory (LSTM) as base classifiers and logistic regression (LR) as a meta classifier\n",
    "   </td>\n",
    "   <td>accuracy,\n",
    "<p>\n",
    "precision, recall, F1 Score\n",
    "   </td>\n",
    "   <td><a href=\"https://www.mdpi.com/2078-2489/12/9/374\">https://www.mdpi.com/2078-2489/12/9/374</a>\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Optimization of sentiment analysis using\n",
    "<p>\n",
    "machine learning classifers\n",
    "   </td>\n",
    "   <td>2017\n",
    "   </td>\n",
    "   <td>three manually compiled datasets; two of them are captured\n",
    "<p>\n",
    "from Amazon and one dataset is assembled from IMDB movie reviews\n",
    "   </td>\n",
    "   <td>Machine Learning\n",
    "   </td>\n",
    "   <td>Naïve\n",
    "<p>\n",
    "Bayes, J48, BFTree and OneR\n",
    "   </td>\n",
    "   <td>accuracy, F-measure, correctly classifed\n",
    "<p>\n",
    "instances\n",
    "   </td>\n",
    "   <td><a href=\"https://doi.org/10.1186/S13673-017-0116-3\">https://doi.org/10.1186/S13673-017-0116-3</a>\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Sentiment Analysis of Short Texts from Social\n",
    "<p>\n",
    "Networks Using Sentiment Lexicons and\n",
    "<p>\n",
    "Blending of Machine Learning Algorithms\n",
    "   </td>\n",
    "   <td>2018\n",
    "   </td>\n",
    "   <td>VKontakte social network posts\n",
    "   </td>\n",
    "   <td>Hybrid\n",
    "   </td>\n",
    "   <td>Logistic Regression, Random Forest Classifier, SVM, Gradient Boosting Classifier, KNeighbors Classifier, Multino-\n",
    "<p>\n",
    "mial Naive Bayes\n",
    "   </td>\n",
    "   <td>F1 Score\n",
    "   </td>\n",
    "   <td>http://ceur-ws.org/Vol-2268/paper21.pdf\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Tweets Classification on the Base of Sentiments for US Airline Companies\n",
    "   </td>\n",
    "   <td>2019\n",
    "   </td>\n",
    "   <td>Twitter US Airline Sentiment\n",
    "   </td>\n",
    "   <td>Machine Learning\n",
    "   </td>\n",
    "   <td>Voting Classifier is based on logistic regression (LR) and stochastic gradient descent classifier (SGDC) <strong>vs</strong> a variety of machine learning classifiers\n",
    "   </td>\n",
    "   <td>accuracy, precision, recall and F1 score\n",
    "   </td>\n",
    "   <td><a href=\"https://doi.org/10.3390/e21111078\">https://doi.org/10.3390/e21111078</a>\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>The Impact of Features Extraction on the Sentiment Analysis\n",
    "   </td>\n",
    "   <td>2019\n",
    "   </td>\n",
    "   <td>Sentiment Strength Twitter Dataset \n",
    "<p>\n",
    "\t\t\t\t\n",
    "<p>\n",
    "\t\t\t\n",
    "<p>\n",
    "\t\t\n",
    "   </td>\n",
    "   <td>Machine Learning\n",
    "   </td>\n",
    "   <td>TFIDF vs N-gram on 6 ML algos (LR, SVM, Decision Tree, Random Forest, KNN, Naive Bayes)\n",
    "   </td>\n",
    "   <td>accuracy, precision, recall and F1 score\n",
    "   </td>\n",
    "   <td>https://www.sciencedirect.com/science/article/pii/S1877050919306593\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>TOPIC MODELLING, SENTIMENT ANALSYS\n",
    "<p>\n",
    "AND CLASSIFICATION OF SHORT-FORM TEXT\n",
    "   </td>\n",
    "   <td>2019\n",
    "   </td>\n",
    "   <td>data was obtained through\n",
    "<p>\n",
    "Twitter and Facebook’s public APIs with Netlytic\n",
    "   </td>\n",
    "   <td>Lexicon-based, Machine Learning, Deep Learning\n",
    "   </td>\n",
    "   <td>LDA (Latent Dirichlet Allocation), \n",
    "<p>\n",
    "LSA (Latent Semantic Allocation) vs LR, SVM and Naive Bayes\n",
    "   </td>\n",
    "   <td>technical performance (perplexity score and topic coherence score), ease of application, as well as\n",
    "<p>\n",
    "proximity to human agent performance on the same problem\n",
    "   </td>\n",
    "   <td>https://local.cis.strath.ac.uk/wp/extras/msctheses/papers/strath_cis_publication_2733.pdf\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Using unsupervised information to improve semi-supervised tweet sentiment classification\n",
    "   </td>\n",
    "   <td>2016\n",
    "   </td>\n",
    "   <td>6 datasets: SemEval 2013, LiveJournal, SMS2013, Twitter2013, Twitter2014, Twitter Sarcasm 2014 \n",
    "   </td>\n",
    "   <td>Machine Learning\n",
    "   </td>\n",
    "   <td>semi-supervised C3E algorithmvs SVM\n",
    "   </td>\n",
    "   <td>F-Scores\n",
    "   </td>\n",
    "   <td>https://www.researchgate.net/publication/295244270_Using_unsupervised_information_to_improve_semi-supervised_tweet_sentiment_classification\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Improving Sentiment Analysis for Social Media Applications Using an Ensemble Deep Learning Language Model\n",
    "   </td>\n",
    "   <td>2021\n",
    "   </td>\n",
    "   <td>3 datasets: own Twitter coronavirus hashtag dataset as well as public review datasets from Amazon and Yelp\n",
    "   </td>\n",
    "   <td>Hybrid\n",
    "   </td>\n",
    "   <td>customized deep learning model with an advanced word embedding technique and create a long short-term memory (LSTM)\n",
    "   </td>\n",
    "   <td>accuracy\n",
    "   </td>\n",
    "   <td>https://pubmed.ncbi.nlm.nih.gov/34660170/\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Enhancing Deep Learning Sentiment Analysis with Ensemble Techniques in Social Applications\n",
    "   </td>\n",
    "   <td>2017\n",
    "   </td>\n",
    "   <td>7 datasets on movie reviews & microblogging \n",
    "   </td>\n",
    "   <td>Deep Learning, Hybrid\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>F1 score\n",
    "   </td>\n",
    "   <td>https://www.researchgate.net/publication/313332224_Enhancing_Deep_Learning_Sentiment_Analysis_with_Ensemble_Techniques_in_Social_Applications\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Machine learning based customer sentiment analysis for recommending shoppers, shops based on customers’ review\n",
    "   </td>\n",
    "   <td>2020\n",
    "   </td>\n",
    "   <td>product data with customer reviews is collected from benchmark Unified computing system (UCS)\n",
    "   </td>\n",
    "   <td>Machine Learning \n",
    "   </td>\n",
    "   <td>Hybrid Recommendation System\n",
    "   </td>\n",
    "   <td>MAPE\n",
    "   </td>\n",
    "   <td>https://link.springer.com/article/10.1007/s40747-020-00155-2\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Sentiment Analysis Using Convolutional Neural Network\n",
    "   </td>\n",
    "   <td>2020\n",
    "   </td>\n",
    "   <td>IMDB movie reviews\n",
    "   </td>\n",
    "   <td>Deep Learning\n",
    "   </td>\n",
    "   <td>RNN, LSTM, CNN,\n",
    "   </td>\n",
    "   <td>accuracy\n",
    "   </td>\n",
    "   <td>https://ieeexplore.ieee.org/abstract/document/7363395\n",
    "   </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Other languages: \n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "   <td><strong>Language</strong>\n",
    "   </td>\n",
    "   <td><strong>Paper Name</strong>\n",
    "   </td>\n",
    "   <td><strong>Year of Publishment</strong>\n",
    "   </td>\n",
    "   <td><strong>Dataset(s)</strong>\n",
    "   </td>\n",
    "   <td><strong>Classification</strong>\n",
    "   </td>\n",
    "   <td><strong>Algorithms</strong>\n",
    "   </td>\n",
    "   <td><strong>Performance Evaluation Criteria</strong>\n",
    "   </td>\n",
    "   <td><strong>Source</strong>\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Arabic\n",
    "   </td>\n",
    "   <td>Deep Bidirectional LSTM Network Learning-Based Sentiment Analysis for Arabic Text\n",
    "   </td>\n",
    "   <td>2021\n",
    "   </td>\n",
    "   <td> six benchmark sentiment analysis datasets\n",
    "   </td>\n",
    "   <td>Deep Learning\n",
    "   </td>\n",
    "   <td> Bidirectional LSTM Network (BiLSTM)\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>https://www.degruyter.com/document/doi/10.1515/jisys-2020-0021/html\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Greek\n",
    "   </td>\n",
    "   <td>A Survey on Sentiment Analysis and Opinion Mining in Greek\n",
    "<p>\n",
    "Social Media\n",
    "   </td>\n",
    "   <td>2021\n",
    "   </td>\n",
    "   <td>self-collected and annotated Greek Social Media Texts \n",
    "   </td>\n",
    "   <td>Deep Learning\n",
    "   </td>\n",
    "   <td>PaloBert, GreekBERT\n",
    "   </td>\n",
    "   <td>F1 Score, Accuracy\n",
    "   </td>\n",
    "   <td>https://doi.org/10.3390/info12080331\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>German\n",
    "   </td>\n",
    "   <td>Sentiment analysis of a German Twitter-Corpus\n",
    "   </td>\n",
    "   <td>2017\n",
    "   </td>\n",
    "   <td>German tweets from a bigger dataset\n",
    "   </td>\n",
    "   <td>Machine Learning\n",
    "   </td>\n",
    "   <td>Multinomial NB,  LinearSVC, Decision Tree Classifier, Maxent Classifier\n",
    "   </td>\n",
    "   <td>F-measure, accuracy\n",
    "   </td>\n",
    "   <td>http://ceur-ws.org/Vol-1917/paper06.pdf\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Spanish\n",
    "   </td>\n",
    "   <td>A case study of Spanish text transformations for twitter sentiment analysis\n",
    "   </td>\n",
    "   <td>2021\n",
    "   </td>\n",
    "   <td>two Spanish datasets\n",
    "   </td>\n",
    "   <td>Machine Learning\n",
    "   </td>\n",
    "   <td>SVM\n",
    "   </td>\n",
    "   <td>accuracy, computing time\n",
    "   </td>\n",
    "   <td>https://www.sciencedirect.com/science/article/abs/pii/S0957417417302312?via%3Dihub\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>(Brazilian) Portuguese\n",
    "   </td>\n",
    "   <td>Analyzing the Brazilian Financial Market Through Portuguese Sentiment Analysis in Social Media\n",
    "   </td>\n",
    "   <td>2018\n",
    "   </td>\n",
    "   <td>self annotated Twitter dataset on financial market\n",
    "   </td>\n",
    "   <td>Machine Learning\n",
    "   </td>\n",
    "   <td>Naive\n",
    "<p>\n",
    "Bayes, Support Vector Machines, Maximum Entropy and Multilayer Perceptron\n",
    "   </td>\n",
    "   <td>accuracy\n",
    "   </td>\n",
    "   <td>https://www.researchgate.net/profile/Arthur-Carosia/publication/336933355_Analyzing_the_Brazilian_Financial_Market_through_Portuguese_Sentiment_Analysis_in_Social_Media/links/5e67edc24585153fb3d5b305/Analyzing-the-Brazilian-Financial-Market-through-Portuguese-Sentiment-Analysis-in-Social-Media.pdf\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>French\n",
    "   </td>\n",
    "   <td>Sentiment Analysis of French Tweets based on Subjective Lexicon Approach: Evaluation of the use of OpenNLP and CoreNLP Tools\n",
    "   </td>\n",
    "   <td>2021\n",
    "   </td>\n",
    "   <td>French tweets using \"Public Opinion Knowledge (POK)\" platform\n",
    "   </td>\n",
    "   <td>Lexicon based in comparison to Machine Learning\n",
    "   </td>\n",
    "   <td>OpenNLP, CoreNLP, dependency analysis implemented by CoreNLP\n",
    "   </td>\n",
    "   <td>precision, F-measure\n",
    "   </td>\n",
    "   <td>https://www.researchgate.net/publication/326514882_Sentiment_Analysis_of_French_Tweets_based_on_Subjective_Lexicon_Approach_Evaluation_of_the_use_of_OpenNLP_and_CoreNLP_Tools\n",
    "   </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272a0201-fbb9-44cd-ac9a-67eb823d6835",
   "metadata": {},
   "source": [
    "### Classifier Benchmarking\n",
    "\n",
    "Benchmarking classifiers using community data sets\n",
    "\n",
    "- introduce data sets, justify choice\n",
    "    - social media texts from twitter (about several domains)\n",
    "    - user reviews from IMDB, Rotten Tomatoes (about movies)\n",
    "- compare classifiers\n",
    "    - baseline model (Traditional ML): \n",
    "    Logistic Regression on TFIDF-based (LASSO) (movie reviews?)\n",
    "    SVM (Twitter?)\n",
    "    - Deep Learning: Hierarchical Attention Network (HAN) / LSTM/CNN/ULMFIT ELMO\n",
    "    - Transformer Model: BERT oder  XLNet: Generalized Autoregressive Pretraining for Language Understanding, albert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766debea",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "   <td><strong>Name</strong>\n",
    "   </td>\n",
    "   <td><strong>Platform</strong>\n",
    "   </td>\n",
    "   <td><strong>Domain</strong>\n",
    "   </td>\n",
    "   <td><strong>Size</strong>\n",
    "   </td>\n",
    "   <td><strong>Evaluation (binary or more)</strong>\n",
    "   </td>\n",
    "   <td><strong>Language</strong>\n",
    "   </td>\n",
    "   <td><strong>Source</strong>\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Twitter US Airline Sentiment\n",
    "   </td>\n",
    "   <td>Twitter \n",
    "   </td>\n",
    "   <td>US Airline user experiences\n",
    "   </td>\n",
    "   <td>3.42 MB\n",
    "   </td>\n",
    "   <td>ternary = positive, negative, neutral\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td>https://www.kaggle.com/crowdflower/twitter-airline-sentiment\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Sentiment140\n",
    "   </td>\n",
    "   <td>Twitter\n",
    "   </td>\n",
    "   <td>user responses to different products, brands, or topics\n",
    "   </td>\n",
    "   <td>228 MB Training (1.600.000) \n",
    "   </td>\n",
    "   <td>0 = negative, \n",
    "<p>\n",
    "2 = neutral, 4 = positive\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td>http://help.sentiment140.com/for-students\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Stanford Sentiment Treebank\n",
    "   </td>\n",
    "   <td>Rotten Tomatoes\n",
    "   </td>\n",
    "   <td>movie reviews\n",
    "   </td>\n",
    "   <td>10.000\n",
    "   </td>\n",
    "   <td>1-25 (25: most positive)\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td>https://nlp.stanford.edu/sentiment/code.html\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Large IMDB Movie Reviews\n",
    "   </td>\n",
    "   <td>IMDB\n",
    "   </td>\n",
    "   <td>movie reviews\n",
    "   </td>\n",
    "   <td>25.000 training, 25.000 test\n",
    "   </td>\n",
    "   <td>binary\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td>https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Polarity v2.0\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>movie reviews\n",
    "   </td>\n",
    "   <td>3MB (1000 positive and 1000 negative processed reviews)\n",
    "   </td>\n",
    "   <td>binary\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td>http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Paper Reviews\n",
    "   </td>\n",
    "   <td>conference of computing\n",
    "   </td>\n",
    "   <td>user’s opinion about a paper\n",
    "   </td>\n",
    "   <td>405\n",
    "   </td>\n",
    "   <td>-2: very negative\n",
    "<p>\n",
    "-1: negative\n",
    "<p>\n",
    "0: neutral\n",
    "<p>\n",
    "1: positive\n",
    "<p>\n",
    "2: very positive\n",
    "   </td>\n",
    "   <td>English, Spanish\n",
    "   </td>\n",
    "   <td>https://archive.ics.uci.edu/ml/datasets/Paper+Reviews\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Multi-Domain Sentiment Dataset\n",
    "   </td>\n",
    "   <td>Amazon\n",
    "   </td>\n",
    "   <td>reviews of amazon products\n",
    "   </td>\n",
    "   <td>unprocessed: 1.9 GB, processed: 19 MB\n",
    "   </td>\n",
    "   <td>reviews contain ratings from 1 to 5 stars (can be converted to binary)\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td>https://www.cs.jhu.edu/~mdredze/datasets/sentiment/\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Opin-Rank Review Dataset\n",
    "   </td>\n",
    "   <td>Tripadvisor, Edmunds\n",
    "   </td>\n",
    "   <td>hotel & car reviews\n",
    "   </td>\n",
    "   <td>300.000\n",
    "   </td>\n",
    "   <td>ratings that can be turned into binary?\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td>https://archive.ics.uci.edu/ml/datasets/opinrank+review+dataset\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Sentiment Lexicons For 81 Languages\n",
    "   </td>\n",
    "   <td>-\n",
    "   </td>\n",
    "   <td>-\n",
    "   </td>\n",
    "   <td>2 text files per language\n",
    "   </td>\n",
    "   <td>binary\n",
    "   </td>\n",
    "   <td>81 languages: Afrikaans to Yiddisch\n",
    "   </td>\n",
    "   <td>https://sites.google.com/site/datascienceslab/projects/multilingualsentiment\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Lexicoder\n",
    "   </td>\n",
    "   <td>-\n",
    "   </td>\n",
    "   <td>-\n",
    "   </td>\n",
    "   <td>2,858 negative sentiment words and 1,709 positive sentiment words\n",
    "   </td>\n",
    "   <td>binary\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td>http://www.snsoroka.com/data-lexicoder/\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>DynaSent\n",
    "   </td>\n",
    "   <td>Dynabench\n",
    "   </td>\n",
    "   <td>naturally occurring sentences with sentences created using the open-source Dynabench Platform\n",
    "   </td>\n",
    "   <td>121,634 sentences\n",
    "   </td>\n",
    "   <td>ternary\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td>https://github.com/cgpotts/dynasent\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Amazon Fine Foods\n",
    "   </td>\n",
    "   <td>Amazon\n",
    "   </td>\n",
    "   <td>product reviews\n",
    "   </td>\n",
    "   <td>5.000.000 reviews\n",
    "   </td>\n",
    "   <td>ratings that can be turned into binary?\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td>https://snap.stanford.edu/data/web-FineFoods.html\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Germeval2017\n",
    "   </td>\n",
    "   <td>Social Media \n",
    "   </td>\n",
    "   <td>messages\n",
    "   </td>\n",
    "   <td>22,000 messages from various social media and web sources\n",
    "   </td>\n",
    "   <td>ternary\n",
    "   </td>\n",
    "   <td>German\n",
    "   </td>\n",
    "   <td>https://sites.google.com/view/germeval2017-absa/data\n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Yelp_polarity_reviews\n",
    "   </td>\n",
    "   <td>Yelp\n",
    "   </td>\n",
    "   <td>business reviews\n",
    "   </td>\n",
    "   <td>600,000 reviews for training, 38,000 for testing\n",
    "   </td>\n",
    "   <td>binary (1 - bad, 2 - good)\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td><a href=\"https://www.kaggle.com/irustandi/yelp-review-polarity\">https://www.kaggle.com/irustandi/yelp-review-polarity</a> \n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Financial PhraseBank\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>financial news (rated as pos/neg/neutral) for investor\n",
    "   </td>\n",
    "   <td>4840 \n",
    "<p>\n",
    "4 configurations available (size depends on the level of agreement of annotators)\n",
    "   </td>\n",
    "   <td>ternary\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td><a href=\"https://github.com/huggingface/datasets/tree/master/datasets/financial_phrasebank\">https://github.com/huggingface/datasets/tree/master/datasets/financial_phrasebank</a> \n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>The SigmaLaw- Aspect-Based-SA dataset\n",
    "   </td>\n",
    "   <td>Court cases\n",
    "   </td>\n",
    "   <td>Legal opinion texts\n",
    "   </td>\n",
    "   <td>2,000 sentences\n",
    "   </td>\n",
    "   <td>ternary\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td><a href=\"https://osf.io/efrqt/\">https://osf.io/efrqt/</a> \n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>Skytrax Users Review Dataset \n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>English\n",
    "   </td>\n",
    "   <td><a href=\"https://github.com/quankiquanki/skytrax-reviews-dataset\">https://github.com/quankiquanki/skytrax-reviews-dataset</a> \n",
    "   </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>\n",
    "   </td>\n",
    "   <td>https://mpqa.cs.pitt.edu/corpora/mpqa_corpus/\n",
    "   </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d034696",
   "metadata": {},
   "source": [
    "#### Dataset: Movie reviews \n",
    "\n",
    "We will compare three classifier on two datasets that contain movie reviews: \n",
    "- IMDB dataset: 50.000 movie reviews \n",
    "- Stanford Sentiment Treebank: 10.000 reviews \n",
    "\n",
    "##### Baseline algorithm\n",
    "This experiment used the popular and simple ML algorithm Logistic Regression as a baseline algorithm. Logistic Regression is a statistical technique capable of predicting a binary outcome. Using the built-in functions of scikit-learn, the Logistic Regression was very easy to build. After loading the data set, the code had to re-create all the words from the pre- processed data set to build an index, which translates all lists of word-indices to strings and then used Term Frequence - Inverse Document Frequency (TF-IDF) as text representation. TF-IDF is a statistical measure used to evaluate how important a word is in a document. First, it computes the Term Frequence (TF) for each review, the Inverse Document Frequency (IDF) using each review and finally, the TF-IDF for each review. It transforms on the Test data which computes the TF for each review, then the TF-IDF for each review using the IDF from the Training data. Finally, the model was fit to classify the sentiment of the movie reviews.\n",
    "\n",
    "##### Deep Learning\n",
    "The DL algorithm of this experiment is an LSTM model, which was built with Keras. Keras is an easy usable, high-level neural network API, which is capable to run on top of either TensorFlow or Theano (Keras Documentation, n.d.). The DL algorithm was built with an LSTM architecture using a Sequential model, which consists of five layers: an embedding layer, two dropout layers, an LSTM layer and an output / dense layer. The Sequential model is a linear stack of layers. \n",
    "\n",
    "##### Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff06ea",
   "metadata": {},
   "source": [
    "### NLP Preprocessing Pipeline\n",
    "Before diving deep into predictive modeling we need to preprocess our textual data. For this task we setup a Preprocessor Class which runs a NLP Pipeline to take care of all necessary preprocessing tasks such as lemmatization, stopword removal and text cleaning with regular expressions. In addition, the Preprocessor also factorizes the label to obtain a binary encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7785f9d1-a22b-4bf7-95a6-061ab6d4986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Preprocessor import Preprocessor\n",
    "\n",
    "config = {\n",
    "    \"name\": \"imdb\",\n",
    "    \"df\": pd.read_csv(\"./data/IMDB.csv\"),\n",
    "    \"text_feature\": \"review\",\n",
    "    \"label\": \"sentiment\"\n",
    "}\n",
    "\n",
    "preprocessor = Preprocessor(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "736d3db7-c60f-479f-851a-272447a3dbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read imdb_preprocessed.parquet.gzip from cache...\n",
      "Successfully read imdb_preprocessed.parquet.gzip into memory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reviewer mention watch oz episode hook right e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production the film technique...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>probably time favorite movie story selflessnes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sure like resurrection date seahunt series tec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>amazing fresh innovative idea air year brillia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>encourage positive comment film look forward w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>like original gut wrenching laughter like movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  reviewer mention watch oz episode hook right e...          0\n",
       "1  wonderful little production the film technique...          0\n",
       "2  think wonderful way spend time hot summer week...          0\n",
       "3  basically family little boy jake think zombie ...          1\n",
       "4  petter mattei love time money visually stunnin...          0\n",
       "5  probably time favorite movie story selflessnes...          0\n",
       "6  sure like resurrection date seahunt series tec...          0\n",
       "7  amazing fresh innovative idea air year brillia...          1\n",
       "8  encourage positive comment film look forward w...          1\n",
       "9  like original gut wrenching laughter like movi...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_imdb = preprocessor.run()\n",
    "preprocessed_imdb.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9fb2f5-6756-4d0f-8ae9-5559502b685d",
   "metadata": {},
   "source": [
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b038b2a8-1a90-4e5b-8ef4-06febb386610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_imdb = preprocessed_imdb['review']\n",
    "y_imdb = preprocessed_imdb['sentiment']\n",
    "\n",
    "X_train_imdb, X_test_imdb, y_train_imdb, y_test_imdb = train_test_split(\n",
    "    X_imdb, y_imdb, test_size = 0.3, random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b714fac5-5185-4986-95b3-3c546ff92e4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dee08db-9e31-4f53-a70c-462ba5eb6d76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_imdb_tfidf: (35000, 5287629)\n",
      "X_test_imdb_tfidf: (15000, 5287629)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "X_train_imdb_tfidf = vectorizer.fit_transform(X_train_imdb)\n",
    "X_test_imdb_tfidf = vectorizer.transform(X_test_imdb)\n",
    "\n",
    "print('X_train_imdb_tfidf:', X_train_imdb_tfidf.shape)\n",
    "print('X_test_imdb_tfidf:', X_test_imdb_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464835c-c60f-4a71-aaa2-e9b18b8bb6c1",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0572b68-0cef-42d8-8378-64f4bd885146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=100, random_state=42)\n",
    "log_reg.fit(X_train_imdb_tfidf, y_train_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "447d1853-df03-49c8-a056-6b95b3beadba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_hat_imdb = log_reg.predict(X_test_imdb_tfidf)\n",
    "print(y_hat_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970b5dd6-9cb3-4075-8c2e-7ce4744956db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8787333333333334\n"
     ]
    }
   ],
   "source": [
    "score = log_reg.score(X_test_imdb_tfidf, y_test_imdb)\n",
    "print(f'accuracy: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a2935c",
   "metadata": {},
   "source": [
    "#### Dataset: Tweets\n",
    "\n",
    "##### Baseline Algorithm\n",
    "\n",
    "##### Deep Learning\n",
    "\n",
    "##### Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8164b2-5f7a-4d1a-929b-d7f32990115c",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "- benchmark ranking of classifiers on different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c39d02f-9855-4f7c-9a9c-d97ebb32394c",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- valuable insights on method selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e9fec",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gaye, B.; Zhang, D.; Wulamu, A. A Tweet Sentiment Classification Approach Using a Hybrid Stacked Ensemble Technique. Information 2021, 12, 374. https://doi.org/10.3390/info12090374\n",
    "Alsayat A. Improving Sentiment Analysis for Social Media Applications Using an Ensemble Deep Learning Language Model. Arab J Sci Eng. 2021 Oct 11:1-13. doi: 10.1007/s13369-021-06227-w. Epub ahead of print. PMID: 34660170; PMCID: PMC8502794.\n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
