{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27fa68ae-687b-4082-bb3d-6ab26b0c2d5b",
   "metadata": {},
   "source": [
    "## Sentiment Analysis: benchmarking state-of-the-art classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a171b2ae-0f7f-4590-a943-300e1aabbbd6",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "What is Sentiment Analysis?\n",
    "- NLP frame, one of many NLP tasks\n",
    "- Definition: extract subjective information to determine polarity\n",
    "- areas of application (e. g. user generated content)\n",
    "- research timeline for SA/ deep learning in NLP (starting 2010s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a6f362",
   "metadata": {},
   "source": [
    "The growth of user-generated content in web sites and social networks, e.g. Twitter, Amazon, Tripadvisor, Rottentomatoes and IMDB has led to an increasing power for expressing opinions. In recent years, the automatic extraction of opinions from a text has become an area of growing interest. Combined with the fast spreading nature of online content, online opinions have turned into a valuable asset. In order to analyze the massive amount of information, many Natural Language Processing (NLP) tasks are being used. In particular, Sentiment Analysis (SA), also known as Opinion Mining (from now on: SA), became an increasingly growing task (Liu, 2015), whose goal it is to classify opinions and sentiments expressed in user-generated text. SA is on the rise due to the increased requirement of analyzing and structuring hidden information, which comes from <span style=\"background-color:yellow\">social media [user-generated content in general?]</span> in the form of unstructured data (Ain, Ali, Riaz, Noureen, Kamran, Hayat & Rehman, 2017). SA allows to detect emotions and sentiment that the author of a text felt towards a described subject or entity. It is interesting in many fields and branches and helps solving various tasks, e.g.:\n",
    "\n",
    "- companies can measure the feedback about a product or service,\n",
    "- sociologists can look at people’s reaction about public events,\n",
    "- psychologists can study the general mind state of communities with regard to various\n",
    "issues, i.e. a depression detection model that is based on SA in micro-blog social\n",
    "networks (Wang, Zhang, Ji, Sun, Wu & Bao, 2013),\n",
    "- governments and political parties are able to correct their actions according to social\n",
    "approval or disapproval,\n",
    "- etc.\n",
    "\n",
    "Sentiments are not always expressed explicitly and meanings can be hidden in the context, where additional word and language knowledge is necessary. Moreover, opinions may involve sarcasm and negations, which can be interpreted differently in various domains and contexts. Sentiment classification is rather easy for humans (Pang, Lee & Vaithyanathan, 2002), but manual review and analysis of texts is very time consuming and thus, expensive. Due to this fact, automatic sentiment classifiers are selected instead. There are three traditional methods how SA can be classified: lexicon-based method, machine learning-based method and hybrid methods, which is mixing the two former methods.\n",
    "\n",
    "Although traditional machine learning algorithms like Support Vector Machines have shown good performance in various NLP tasks for the past few decades, they have a few shortcomings, where <span style=\"background-color:yellow\">DL models [wird erst im nächsten Satz definiert]</span> have the potential to overcome these limitations to a large extent. \n",
    "A promising alternative to traditional machine learning based methods is Deep Learning (DL). It has shown excellent performance in NLP tasks, including Sentiment Analysis (Collobert, Weston, Bottou, Karlen, Kavukcuglu & Kuksa, 2011). The main idea of DL is to learn complex features extracted from data using deep neural networks with a minimum of external human contribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff969c0",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis: <span style=\"background-color:yellow\">Definition & Classification [wurde oben bereits definiert?]</span> \n",
    "\n",
    "Sentiment Analysis, also known as opinion mining or sentiment polarity, is an active research area in NLP that refers to the use of text analysis, statistical learning and often Machine Learning to extract subjective information in source materials such as user-generated texts from social networks, blogs, forums and product or service reviews.\n",
    "Selecting the basic emotions is a difficult task for a computer because of the variety of human emotions. Most of the authors in the NLP community agree on the classification proposed by Ekman, Friesen and Ellsworth (1982), who mentioned that six basic emotions exist: anger, disgust, fear, joy, sadness and surprise. Such a division requires a complex processing and analysis of the input data, which is most of the time not feasible. Therefore, the majority of researchers and authors accept a simpler representation of sentiments according to their polarity (Pang & Lee, 2008). Kurosu (2015) defines sentiment polarity as follows: “The polarity of a sentiment is the point on the evaluation scale that corresponds to our positive or negative evaluation of the meaning of this sentiment.”. Sentiment polarity allows researchers to use a single dimension, either positive or negative and therefore, simplifies the representation and management of the sentiment information.\n",
    "Liu (2012) presented three levels of SA: (i) document level, (ii) sentence level and (iii) entity / aspect level. Document level studies the polarity of the whole text with respect to a single entity (e.g. a product). Sentence level studies the polarity of sentences, analyzing clauses and phrases for its sentiment. Entity / aspect level analyzes what people especially liked or disliked. An entity-aspect might be a single token and its polarity might be different from the overall polarity of the text (Liu, 2012).\n",
    "The granularity of SA can be either coarse-grained or fine-grained. Coarse-grained means usually a binary classification (positive, negative). On ther other hand, fine-grained uses for example five possible levels of granularity (high positive, low positive, neutral, low negative, high negative).\n",
    "\n",
    "Application:\n",
    "\n",
    "- product reviews,\n",
    "- customer e-mails about a product or service,\n",
    "- people’s reaction on Twitter about an advertising, a campaign, a product release, etc.,\n",
    "- blogs / news articles about recent topics, e.g. the presidential election.\n",
    "\n",
    "Classification:\n",
    "\n",
    "All methods used to solve sentiment classification fall into three main categories: lexicon-based, machine learning-based and hybrid approaches.\n",
    "In knowledge-based approaches, also called lexicon-based approaches, sentiment is seen as a function of keywords and usually, is based on their count. The main task is the construction of sentiment word lexicons with the indicated class labels positive or negative. In some cases also with their intensiveness, which becomes important for a fine-grained classification.\n",
    "An alternative to the knowledge-based method is Machine Learning, which is gaining more and more interest of researchers due to its adaptability and higher accuracy. <span style=\"background-color:yellow\">Currently, Machine Learning methods are the dominant approach in SA (Pang et al., 2002). The three main algorithms are Naïve Bayes (NB), Support Vector Machines (SVM) and Maximum Entropy (MaxEnt, in Statistics called: Logisitic Regression). [This seems a little bit outdated? The source is from 2002 :D]</span>\n",
    "The hybrid approach, also known as combined analysis, combines both knowledge-based and machine learning-based methods and thus, can lead to a superior performance. Researchers were attracted to explore the possibility of a hybrid approach that collectively could exhibit the accuracy of a machine learning approach and the speed of a lexical approach.\n",
    "\n",
    "Transformer???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5159d44-5fe5-440b-b8b6-6d5e6333fb21",
   "metadata": {},
   "source": [
    "### Research Overview\n",
    "\n",
    "- brief historical overview\n",
    "- research/literature streams and focus\n",
    "- what is the state-of-the-art research towards 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272a0201-fbb9-44cd-ac9a-67eb823d6835",
   "metadata": {},
   "source": [
    "### Classifier Benchmarking\n",
    "\n",
    "Benchmarking classifiers using community data sets\n",
    "\n",
    "- introduce data sets, justify choice\n",
    "    - social media texts from twitter (about several domains)\n",
    "    - user reviews from IMDB, Rotten Tomatoes (about movies)\n",
    "- compare classifiers\n",
    "    - baseline model (Traditional ML): \n",
    "    Logistic Regression on TFIDF-based (LASSO) (movie reviews?)\n",
    "    SVM (Twitter?)\n",
    "    - Deep Learning: Hierarchical Attention Network (HAN) / LSTM/CNN/ULMFIT ELMO\n",
    "    - Transformer Model: BERT oder  XLNet: Generalized Autoregressive Pretraining for Language Understanding, albert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d034696",
   "metadata": {},
   "source": [
    "#### Dataset: Movie reviews \n",
    "\n",
    "We will compare three classifier on two datasets that contain movie reviews: \n",
    "- IMDB dataset: 50.000 movie reviews \n",
    "- Stanford Sentiment Treebank: 10.000 reviews \n",
    "\n",
    "##### Baseline algorithm\n",
    "This experiment used the popular and simple ML algorithm Logistic Regression as a baseline algorithm. Logistic Regression is a statistical technique capable of predicting a binary outcome. Using the built-in functions of scikit-learn, the Logistic Regression was very easy to build. After loading the data set, the code had to re-create all the words from the pre- processed data set to build an index, which translates all lists of word-indices to strings and then used Term Frequence - Inverse Document Frequency (TF-IDF) as text representation. TF-IDF is a statistical measure used to evaluate how important a word is in a document. First, it computes the Term Frequence (TF) for each review, the Inverse Document Frequency (IDF) using each review and finally, the TF-IDF for each review. It transforms on the Test data which computes the TF for each review, then the TF-IDF for each review using the IDF from the Training data. Finally, the model was fit to classify the sentiment of the movie reviews.\n",
    "\n",
    "##### Deep Learning\n",
    "The DL algorithm of this experiment is an LSTM model, which was built with Keras. Keras is an easy usable, high-level neural network API, which is capable to run on top of either TensorFlow or Theano (Keras Documentation, n.d.). The DL algorithm was built with an LSTM architecture using a Sequential model, which consists of five layers: an embedding layer, two dropout layers, an LSTM layer and an output / dense layer. The Sequential model is a linear stack of layers. \n",
    "\n",
    "##### Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff06ea",
   "metadata": {},
   "source": [
    "### NLP Preprocessing Pipeline\n",
    "Before diving deep into predictive modeling we need to preprocess our textual data. For this task we setup a Preprocessor Class which runs a NLP Pipeline to take care of all necessary preprocessing tasks such as lemmatization, stopword removal and text cleaning with regular expressions. In addition, the Preprocessor also factorizes the label to obtain a binary encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7785f9d1-a22b-4bf7-95a6-061ab6d4986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Preprocessor import Preprocessor\n",
    "\n",
    "config = {\n",
    "    \"name\": \"imdb\",\n",
    "    \"df\": pd.read_csv(\"./data/IMDB.csv\"),\n",
    "    \"text_feature\": \"review\",\n",
    "    \"label\": \"sentiment\"\n",
    "}\n",
    "\n",
    "preprocessor = Preprocessor(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "736d3db7-c60f-479f-851a-272447a3dbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read imdb_preprocessed.parquet.gzip from cache...\n",
      "Successfully read imdb_preprocessed.parquet.gzip into memory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reviewer mention watch oz episode hook right e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production the film technique...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>probably time favorite movie story selflessnes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sure like resurrection date seahunt series tec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>amazing fresh innovative idea air year brillia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>encourage positive comment film look forward w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>like original gut wrenching laughter like movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  reviewer mention watch oz episode hook right e...          0\n",
       "1  wonderful little production the film technique...          0\n",
       "2  think wonderful way spend time hot summer week...          0\n",
       "3  basically family little boy jake think zombie ...          1\n",
       "4  petter mattei love time money visually stunnin...          0\n",
       "5  probably time favorite movie story selflessnes...          0\n",
       "6  sure like resurrection date seahunt series tec...          0\n",
       "7  amazing fresh innovative idea air year brillia...          1\n",
       "8  encourage positive comment film look forward w...          1\n",
       "9  like original gut wrenching laughter like movi...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_imdb = preprocessor.run()\n",
    "preprocessed_imdb.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9fb2f5-6756-4d0f-8ae9-5559502b685d",
   "metadata": {},
   "source": [
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b038b2a8-1a90-4e5b-8ef4-06febb386610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_imdb = preprocessed_imdb['review']\n",
    "y_imdb = preprocessed_imdb['sentiment']\n",
    "\n",
    "X_train_imdb, X_test_imdb, y_train_imdb, y_test_imdb = train_test_split(\n",
    "    X_imdb, y_imdb, test_size = 0.3, random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b714fac5-5185-4986-95b3-3c546ff92e4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dee08db-9e31-4f53-a70c-462ba5eb6d76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_imdb_tfidf: (35000, 5287629)\n",
      "X_test_imdb_tfidf: (15000, 5287629)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "X_train_imdb_tfidf = vectorizer.fit_transform(X_train_imdb)\n",
    "X_test_imdb_tfidf = vectorizer.transform(X_test_imdb)\n",
    "\n",
    "print('X_train_imdb_tfidf:', X_train_imdb_tfidf.shape)\n",
    "print('X_test_imdb_tfidf:', X_test_imdb_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464835c-c60f-4a71-aaa2-e9b18b8bb6c1",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0572b68-0cef-42d8-8378-64f4bd885146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=100, random_state=42)\n",
    "log_reg.fit(X_train_imdb_tfidf, y_train_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "447d1853-df03-49c8-a056-6b95b3beadba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_hat_imdb = log_reg.predict(X_test_imdb_tfidf)\n",
    "print(y_hat_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970b5dd6-9cb3-4075-8c2e-7ce4744956db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8787333333333334\n"
     ]
    }
   ],
   "source": [
    "score = log_reg.score(X_test_imdb_tfidf, y_test_imdb)\n",
    "print(f'accuracy: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a2935c",
   "metadata": {},
   "source": [
    "#### Dataset: Tweets\n",
    "\n",
    "##### Baseline Algorithm\n",
    "- SVM?\n",
    "\n",
    "##### Deep Learning\n",
    "\n",
    "##### Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8164b2-5f7a-4d1a-929b-d7f32990115c",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "- benchmark ranking of classifiers on different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c39d02f-9855-4f7c-9a9c-d97ebb32394c",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- valuable insights on method selection\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
